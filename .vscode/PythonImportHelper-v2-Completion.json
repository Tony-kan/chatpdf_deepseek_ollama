[
    {
        "label": "PyPDFLoader",
        "importPath": "langchain_community.document_loaders",
        "description": "langchain_community.document_loaders",
        "isExtraImport": true,
        "detail": "langchain_community.document_loaders",
        "documentation": {}
    },
    {
        "label": "RecursiveCharacterTextSplitter",
        "importPath": "langchain_text_splitters",
        "description": "langchain_text_splitters",
        "isExtraImport": true,
        "detail": "langchain_text_splitters",
        "documentation": {}
    },
    {
        "label": "InMemoryVectorStore",
        "importPath": "langchain_core.vectorstores",
        "description": "langchain_core.vectorstores",
        "isExtraImport": true,
        "detail": "langchain_core.vectorstores",
        "documentation": {}
    },
    {
        "label": "FAISS",
        "importPath": "langchain_core.vectorstores",
        "description": "langchain_core.vectorstores",
        "isExtraImport": true,
        "detail": "langchain_core.vectorstores",
        "documentation": {}
    },
    {
        "label": "OllamaEmbeddings",
        "importPath": "langchain_ollama",
        "description": "langchain_ollama",
        "isExtraImport": true,
        "detail": "langchain_ollama",
        "documentation": {}
    },
    {
        "label": "OllamaLLM",
        "importPath": "langchain_ollama.llms",
        "description": "langchain_ollama.llms",
        "isExtraImport": true,
        "detail": "langchain_ollama.llms",
        "documentation": {}
    },
    {
        "label": "ChatPromptTemplate",
        "importPath": "langchain_core.prompts",
        "description": "langchain_core.prompts",
        "isExtraImport": true,
        "detail": "langchain_core.prompts",
        "documentation": {}
    },
    {
        "label": "upload_pdf",
        "kind": 2,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "def upload_pdf(file):\n    \"\"\"\n    Uploads a pdf file to the pdf_directory.\n    Args:\n        file: the file to upload\n    Returns:\n        None\n    \"\"\"\n    with open(pdf_directory + file.name, \"wb\") as f:\n        f.write(file.getbuffer())",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "create_vector_store",
        "kind": 2,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "def create_vector_store(file_path):\n    \"\"\"\n    Creates a vector store from a given pdf file.\n    Args:\n        file_path: the file path to the pdf file\n    Returns:\n        the vector store\n    \"\"\"\n    loader = PyPDFLoader(file_path)\n    documents = loader.load()",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "retriev_docs",
        "kind": 2,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "def retriev_docs(db,query,k=4):\n    print(db.similarity_search(query))\n    return db.similarity_search(query,k)\ndef question_pdf(question,documents):\n    context = \"\\n\\n\".join([doc.page_content for doc in documents])\n    prompt = ChatPromptTemplate.from_template(template)\n    chain = prompt | model\n    return chain.invoke({\"question\": question, \"context\": context})",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "question_pdf",
        "kind": 2,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "def question_pdf(question,documents):\n    context = \"\\n\\n\".join([doc.page_content for doc in documents])\n    prompt = ChatPromptTemplate.from_template(template)\n    chain = prompt | model\n    return chain.invoke({\"question\": question, \"context\": context})",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "pdf_directory",
        "kind": 5,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "pdf_directory = \"pdfs/\"\nembeddings = OllamaEmbeddings(model=\"deepseek-r1:7.6b\")\nmodel = OllamaLLM(\n    model=\"deepseek-r1:7.6b\",\n    temperature=0)\ntemplate = \"\"\"\nYou are an assistant that answers questions. Using the following retrieved information, answer the user\nquestion. If  you don't know the answer, say that you don't know, don't try to make up an answer.\nUse up to three sentences, keeping the answer brief and concise.\nQuestion: {question}",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "embeddings",
        "kind": 5,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "embeddings = OllamaEmbeddings(model=\"deepseek-r1:7.6b\")\nmodel = OllamaLLM(\n    model=\"deepseek-r1:7.6b\",\n    temperature=0)\ntemplate = \"\"\"\nYou are an assistant that answers questions. Using the following retrieved information, answer the user\nquestion. If  you don't know the answer, say that you don't know, don't try to make up an answer.\nUse up to three sentences, keeping the answer brief and concise.\nQuestion: {question}\nContext: {context}",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "model",
        "kind": 5,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "model = OllamaLLM(\n    model=\"deepseek-r1:7.6b\",\n    temperature=0)\ntemplate = \"\"\"\nYou are an assistant that answers questions. Using the following retrieved information, answer the user\nquestion. If  you don't know the answer, say that you don't know, don't try to make up an answer.\nUse up to three sentences, keeping the answer brief and concise.\nQuestion: {question}\nContext: {context}\nAnswer:",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "template",
        "kind": 5,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "template = \"\"\"\nYou are an assistant that answers questions. Using the following retrieved information, answer the user\nquestion. If  you don't know the answer, say that you don't know, don't try to make up an answer.\nUse up to three sentences, keeping the answer brief and concise.\nQuestion: {question}\nContext: {context}\nAnswer:\n\"\"\"\ndef upload_pdf(file):\n    \"\"\"",
        "detail": "main",
        "documentation": {}
    }
]